# GCD-TFG App: AutomatizaciÃ³n de presupuestos personalizados mediante Large Language Models

## ğŸ“– DescripciÃ³n

Este repositorio presenta el trabajo realizado en mi **Trabajo Final de Grado en Ciencia de Datos** en la **Universidad PolitÃ©cnica de Valencia**, titulado **"AutomatizaciÃ³n de presupuestos personalizados mediante Large Language Models"**.

El proyecto implementa mÃºltiples agentes de IA especializados en la elaboraciÃ³n automÃ¡tica de presupuestos para productos industriales, especÃ­ficamente para la empresa **Grantlamp**. La soluciÃ³n combina:

- **LangGraph**: para definir flujos de trabajo (DAGs) que cargan datos estructurados, razonan sobre costes y estiman precios
- **OpenRouter API**: para acceso a modelos LLM de gran escala (Claude, Gemini, Mistral)
- **Ollama**: para ejecuciÃ³n local de modelos open-source (Llama, Qwen)
- **LangGraph Platform**: servidor local para despliegue y gestiÃ³n de agentes
- **AnÃ¡lisis comparativo**: evaluaciÃ³n sistemÃ¡tica del rendimiento de diferentes arquitecturas de agentes

## ğŸ¤– Agentes Implementados

El proyecto incluye **6 agentes especializados** con diferentes arquitecturas y modelos:

### Agentes MonolÃ­ticos (Single-Agent)
- **`graph_monolith_claude`**: Agente Ãºnico con Claude 3.5 Sonnet (OpenRouter)
- **`graph_monolith_gemini`**: Agente Ãºnico con Gemini 2.0 Flash (OpenRouter) 
- **`graph_monolith_mistral`**: Agente Ãºnico con Mistral Large 2411 (OpenRouter)
- **`graph_monolith_llama`**: Agente Ãºnico con Llama 3.1 (Ollama local)
- **`graph_monolith_qwen`**: Agente Ãºnico con Qwen 2.5 (Ollama local)

### Agente Multi-Agente (Dual Architecture)
- **`graph_dual_mix`**: Arquitectura dual con Manager (Llama 3.1) + Coder (Qwen 2.5) ejecutÃ¡ndose en Ollama

> **Arquitecturas**: Los agentes *monolÃ­ticos* utilizan una sola herramienta de procesamiento de texto, mientras que el agente *dual* implementa una arquitectura multi-agente donde el Manager coordina las tareas y el Coder ejecuta las estimaciones tÃ©cnicas.

## ğŸš€ CaracterÃ­sticas principales

- **MÃºltiples proveedores LLM**: Soporte para OpenRouter (modelos grandes) y Ollama (modelos locales)
- **Acceso al Maestro de Componentes**: BÃºsqueda inteligente de piezas similares y precios histÃ³ricos
- **EstimaciÃ³n automÃ¡tica**: GeneraciÃ³n de presupuestos completos con razonamiento paso a paso
- **AnÃ¡lisis de rendimiento**: EvaluaciÃ³n comparativa con mÃ©tricas de eficiencia y calidad
- **Arquitecturas diversas**: ComparaciÃ³n entre enfoques monolÃ­ticos y multi-agente

## ğŸ“Š EvaluaciÃ³n y AnÃ¡lisis

El proyecto incluye un **anÃ¡lisis exhaustivo del rendimiento** de los agentes, evaluando:

### MÃ©tricas de Calidad (EvaluaciÃ³n Humana)
- **Acceso (0-2)**: Capacidad para acceder y utilizar correctamente el Maestro de Componentes
- **AdecuaciÃ³n (0-10)**: PrecisiÃ³n tÃ©cnica y coherencia de la respuesta generada

### MÃ©tricas de Eficiencia (Objetivas)
- **Tokens consumidos**: Uso de recursos computacionales
- **Tiempo de inferencia**: Velocidad de respuesta
- **Coste econÃ³mico**: AnÃ¡lisis coste-beneficio por presupuesto

> **Resultados clave**: Los modelos locales de Ollama no lograron completar la tarea de presupuestaciÃ³n completa, mientras que los modelos grandes (Claude, Gemini, Mistral) a travÃ©s de OpenRouter mostraron diferentes perfiles de rendimiento segÃºn la mÃ©trica evaluada.

## ğŸ› ï¸ Prerrequisitos

- **Python 3.11+**
- **Docker** (>=24) y **docker-compose**
- **Node.js 20** y **npm** (opcional, para desarrollo frontend)
- **Git**
- **API Keys**: OpenRouter API key para modelos externos

## ğŸ“ Estructura del proyecto

```text
GCD-TFG-app/
â”œâ”€â”€ backend/
â”‚   â””â”€â”€ src/
â”‚       â””â”€â”€ my_langgraph/
â”‚           â”œâ”€â”€ agent.py          # DefiniciÃ³n de todos los agentes
â”‚           â”œâ”€â”€ tools/             # Herramientas de acceso al Maestro de Componentes
â”‚           â””â”€â”€ prompts/           # Templates de prompts especializados
â”œâ”€â”€ evaluation/
â”‚   â”œâ”€â”€ analisis.ipynb            # AnÃ¡lisis comparativo de resultados
â”‚   â””â”€â”€ data/                     # Datos de evaluaciÃ³n y mÃ©tricas
â”œâ”€â”€ frontend/ui-budget/           # Interfaz de usuario (Assistant-UI)
â”œâ”€â”€ models/ollama/                # Modelos locales (bind-mount)
â”œâ”€â”€ ops/
â”‚   â””â”€â”€ docker-compose.dev.yml    # ConfiguraciÃ³n de desarrollo
â”œâ”€â”€ langgraph.json               # ConfiguraciÃ³n LangGraph Platform
â””â”€â”€ README.md
```

## âš™ï¸ ConfiguraciÃ³n del entorno

### 1. ConfiguraciÃ³n inicial
```bash
git clone <repo_url>.git
cd GCD-TFG-app
mkdir -p models/ollama
```

### 2. Variables de entorno
Crea un archivo `.env` con:
```bash
OPENROUTER_API_KEY=tu_openrouter_api_key
LANGCHAIN_API_KEY=tu_langchain_api_key  # Opcional, para tracing
```

### 3. Levantar servicios con Docker
```bash
docker-compose -f ops/docker-compose.dev.yml up --build
```

### 4. Servidor LangGraph local
Para ejecutar los agentes localmente usando LangGraph Platform:
```bash
# Instalar dependencias
pip install -e ./backend

# Ejecutar servidor local
langgraph dev
```

Ver [documentaciÃ³n oficial](https://langchain-ai.github.io/langgraph/tutorials/langgraph-platform/local-server/) para mÃ¡s detalles.

## ğŸ“¥ GestiÃ³n de modelos

### Modelos Ollama (Locales)
```bash
# Acceder al contenedor
docker-compose exec llm bash

# Descargar modelos necesarios
ollama pull llama3.1:8b
ollama pull qwen2.5:7b
```

### Modelos OpenRouter (Externos)
Los siguientes modelos se acceden vÃ­a API:
- Claude 3.5 Sonnet
- Gemini 2.0 Flash  
- Mistral Large 2411

## ğŸ”¬ Ejecutar evaluaciones

Para reproducir el anÃ¡lisis comparativo:

```bash
# Ejecutar notebook de anÃ¡lisis
jupyter notebook evaluation/analisis.ipynb

# O usando el entorno Docker
docker-compose exec backend jupyter notebook --allow-root
```

## ğŸ’¡ Caso de uso: Grantlamp

El sistema estÃ¡ optimizado para generar presupuestos de productos industriales para **Grantlamp**, integrando:

- **14-18 componentes** por presupuesto tÃ­pico
- **Acceso al Maestro de Componentes** (base de datos propietaria)
- **EstimaciÃ³n de precios** basada en similitudes y precios histÃ³ricos
- **Razonamiento tÃ©cnico** paso a paso documentado

### Ejemplo de flujo:
1. El usuario solicita un presupuesto con especificaciones tÃ©cnicas
2. El agente accede al Maestro de Componentes para buscar piezas similares
3. Se calculan estimaciones basadas en precios histÃ³ricos y ajustes tÃ©cnicos
4. Se genera un presupuesto detallado con justificaciÃ³n de cada componente

## ğŸ“ˆ Resultados del TFG

## ğŸ“ˆ Resultados del TFG

### Principales hallazgos:

#### ğŸ¯ **ConclusiÃ³n estratÃ©gica clave**
Tras evaluar mÃºltiples enfoques tecnolÃ³gicos, **el GPT privado de OpenAI se consolida como la soluciÃ³n Ã³ptima**, ofreciendo el mejor balance calidad-coste-previsibilidad para la automatizaciÃ³n de presupuestos.

#### ğŸ” **EvaluaciÃ³n comparativa de modelos**
- **GPT y Claude 3.5 Sonnet**: LÃ­deres indiscutibles en calidad tÃ©cnica y coherencia
- **Gemini 2.0 Flash**: MÃ¡s econÃ³mico y rÃ¡pido, pero con menor finura en el razonamiento  
- **Mistral Large 2411**: Rendimiento intermedio con buena velocidad de respuesta
- **Modelos locales (8B parÃ¡metros)**: **Descartados** por incapacidad para seguir consistentemente la metodologÃ­a de negocio

#### âš–ï¸ **Trade-offs tecnolÃ³gicos identificados**
- **LLMaaS vs. Autoalojado**: Las soluciones como servicio minimizan drÃ¡sticamente la carga de DevOps
- **Calidad vs. Coste**: Claude ofrece mÃ¡xima calidad pero con alto coste y latencia; Gemini es econÃ³mico pero menos preciso
- **SoberanÃ­a vs. Practicidad**: El autoalojamiento garantiza control total de datos pero introduce complejidad operativa prohibitiva

#### ğŸ“Š **Impacto operativo medido**
- **ReducciÃ³n del tiempo de presupuestaciÃ³n: >50%**
- **PrecisiÃ³n mantenida: Â±10%** respecto a estimaciÃ³n experta
- **MetodologÃ­a "piezas de lego"**: Validada y aceptada por usuarios finales en entorno de producciÃ³n

#### ğŸ—ï¸ **Complejidad de desarrollo**
- **GPT privado**: Mantenimiento marginal centrado en mejora de prompts
- **LangGraph + Assistant-UI**: Requiere CI/CD completo, monitorizaciÃ³n y soporte especializado continuo
- **Modelos pequeÃ±os autoalojados**: Inviables por inconsistencia en seguimiento de lÃ³gica de negocio

### Publicaciones y documentaciÃ³n:
- Memoria completa del TFG (disponible tras defensa)
- AnÃ¡lisis estadÃ­stico en `evaluation/analisis.ipynb`
- MÃ©tricas detalladas por agente y sesiÃ³n de prueba

## ğŸ¤ Contribuciones

Este es un proyecto acadÃ©mico, pero las contribuciones son bienvenidas para:
- Mejoras en las arquitecturas de agentes
- Nuevos modelos o proveedores LLM
- Optimizaciones en las mÃ©tricas de evaluaciÃ³n
- Extensiones para otros dominios industriales

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo la licencia MIT. VÃ©ase `LICENSE` para mÃ¡s detalles.

---

**Trabajo Final de Grado** | **Universidad PolitÃ©cnica de Valencia** | **Grado en Ciencia de Datos**